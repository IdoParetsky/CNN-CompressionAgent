{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Classification.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "i5pcljKozO0R",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qxG7fi2_dqcJ",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def int_to_onehot(self, indx):\n",
    "        one_hot = torch.zeros(range_y).float()\n",
    "        one_hot[int(indx)] = 1.0\n",
    "        return one_hot\n",
    "\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y= y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.int_to_onehot(self.y[idx])\n",
    "\n",
    "def train_model(net, X_train, Y_train, X_val, Y_val):\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "    dataSet = Dataset(X_train, Y_train)\n",
    "    trainLoader = torch.utils.data.DataLoader(dataSet, batch_size=64, shuffle=True)\n",
    "    net = net.float()\n",
    "\n",
    "    for epoch in range(100):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, batch in enumerate(trainLoader, 0):\n",
    "            curr_x, curr_y = batch\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(curr_x.to(device).float())\n",
    "            curr_y = torch.max(curr_y, 1)[1]\n",
    "            loss = loss_func(outputs, curr_y.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, pred = torch.max(outputs, -1)\n",
    "\n",
    "        train_output = torch.argmax(netX(torch.Tensor(X_train).to(device).float()).detach().cpu(),1)\n",
    "        train_acc = accuracy_score(train_output, Y_train)\n",
    "        validation_output = torch.argmax(netX(torch.Tensor(X_val).to(device).float()).detach().cpu(),1)\n",
    "        validation_acc = accuracy_score(validation_output, Y_val)\n",
    "\n",
    "        # if (epoch == 99):\n",
    "        #     print(\"Epoch : {}, train acc : {}, train loss : {}, validation acc : {}\".format(epoch + 1, train_acc, running_loss, validation_acc))\n",
    "        # running_loss = 0.00\n",
    "    return optimizer, loss_func\n",
    "\n",
    "\n",
    "class NetX(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NetX, self).__init__()\n",
    "        layers = []\n",
    "        layers_count = np.random.randint(1,7)\n",
    "        layer_neuron_size = list(range(100,1100, 100))\n",
    "        last_size = X.shape[1]\n",
    "        \n",
    "        for i in range(layers_count):\n",
    "            layer_size = np.random.choice(layer_neuron_size, 1)[0]\n",
    "            \n",
    "            norm = np.random.random()\n",
    "            \n",
    "            if (norm <= 0.33):\n",
    "                layers.append(nn.Dropout())\n",
    "            elif (norm <= 0.66):\n",
    "                layers.append(nn.BatchNorm1d(last_size))\n",
    "                        \n",
    "            layers.append(nn.Linear(last_size, layer_size))\n",
    "            \n",
    "            activation = np.random.random()\n",
    "            \n",
    "            if (activation < 0.05):\n",
    "                layers.append(nn.Tanh())\n",
    "            elif (activation < 0.1):\n",
    "                layers.append(nn.Sigmoid(dim=1))\n",
    "            else : \n",
    "                layers.append(nn.ReLU())\n",
    "                \n",
    "            last_size = layer_size\n",
    "                \n",
    "        layers.append(nn.Linear(last_size, int(range_y)))\n",
    "        layers.append(nn.Softmax())\n",
    "\n",
    "        self.model =  nn.Sequential(*layers)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xHL7XIysdFPg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-F0JKvLO6Uco",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "dataset_names=[\n",
    "  # '‪analcatdata_lawsuit‬‏',\n",
    "  # 'ar4',\n",
    "  # 'baseball',\n",
    "  # 'bodyfat',\n",
    "  # 'chatfield_4',\n",
    "  # 'chscase_vine1',\n",
    "  # 'diabetes',\n",
    "  # 'diggle_table_a2',\n",
    "  # 'disclosure_z',\n",
    "  # 'elusage',\n",
    "  # 'fri_c0_250_5',\n",
    "  # 'kc3',\n",
    "  # 'lowbwt',\n",
    "  # 'lupus',\n",
    "  # # Important - with many classes!!\n",
    "  # 'mfeat-karhunen',\n",
    "  'mfeat-morphological',\n",
    "  'no2',\n",
    "  'pm10',\n",
    "  'prnn_synth',\n",
    "  'rabe_131',\n",
    "  'rmftsa_sleepdata',\n",
    "  'schlvote',\n",
    "  'tae',\n",
    "  'teachingAssistant',\n",
    "  'transplant',\n",
    "  'triazines',\n",
    "  'veteran'\n",
    "]\n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FaNSSoo_YCMB",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "977d8c69-ff21-4ce4-e48e-bc7f3c774c43"
   },
   "source": [
    "for dataset_name in dataset_names:\n",
    "  print(\"==================================================================================\")\n",
    "  print(\"Starting dataset \", dataset_name)\n",
    "  PATH = '/content/drive/My Drive/Fully Connected Training/Classification/' + dataset_name + '/'\n",
    "\n",
    "  df = pd.read_csv(PATH+dataset_name+'.csv')\n",
    "\n",
    "  for col in df.columns:\n",
    "    df[col] = df[col].astype(float)\n",
    "\n",
    "\n",
    "  dataset = df.values\n",
    "  X = dataset[:,0:dataset.shape[1] - 1]\n",
    "  Y = dataset[:,dataset.shape[1] - 1]\n",
    "\n",
    "  min_y = min(Y)\n",
    "  max_y = max(Y)\n",
    "\n",
    "  range_y = int(max_y - min_y + 1)\n",
    "\n",
    "  min_max_scaler = preprocessing.MinMaxScaler()\n",
    "  X_scale = min_max_scaler.fit_transform(X)\n",
    "  df_to_csv = pd.DataFrame(X_scale)\n",
    "  df_to_csv.to_csv(PATH + \"./X_to_train.csv\", index = False)\n",
    "\n",
    "  df_to_csv = pd.DataFrame(Y)\n",
    "  df_to_csv.to_csv(PATH + \"./Y_to_train.csv\", index = False)\n",
    "\n",
    "\n",
    "  X_train, X_val, Y_train, Y_val = train_test_split(X_scale, Y, test_size=0.3, random_state=0)\n",
    "\n",
    "  \n",
    "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "  for i in range(30):\n",
    "      # print(\"Starting net \", i)\n",
    "      netX = NetX()\n",
    "      netX.to(device)\n",
    "      optimizer, loss = train_model(netX, X_train, Y_train, X_val, Y_val)\n",
    "\n",
    "      checkpoint = {'model': netX,\n",
    "                    'state_dict': netX.state_dict(),\n",
    "                    'optimizer' : optimizer.state_dict(),\n",
    "                    'mission_type': \"Classification\",\n",
    "                    'loss': loss  \n",
    "                  }\n",
    "                    \n",
    "      torch.save(checkpoint, PATH + 'netX{}model.pt'.format(i))\n",
    "      print(\"Saved net \", i)\n",
    "      # print(\"===================================================================\")\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "==================================================================================\n",
      "Starting dataset  mfeat-morphological\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type NetX. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Saved net  0\n",
      "Saved net  1\n",
      "Saved net  2\n",
      "Saved net  3\n",
      "Saved net  4\n",
      "Saved net  5\n",
      "Saved net  6\n",
      "Saved net  7\n",
      "Saved net  8\n",
      "Saved net  9\n",
      "Saved net  10\n",
      "Saved net  11\n",
      "Saved net  12\n",
      "Saved net  13\n",
      "Saved net  14\n",
      "Saved net  15\n",
      "Saved net  16\n",
      "Saved net  17\n",
      "Saved net  18\n",
      "Saved net  19\n",
      "Saved net  20\n",
      "Saved net  21\n",
      "Saved net  22\n",
      "Saved net  23\n",
      "Saved net  24\n",
      "Saved net  25\n",
      "Saved net  26\n",
      "Saved net  27\n",
      "Saved net  28\n",
      "Saved net  29\n",
      "==================================================================================\n",
      "Starting dataset  no2\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type NetX. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Saved net  0\n",
      "Saved net  1\n",
      "Saved net  2\n",
      "Saved net  3\n",
      "Saved net  4\n",
      "Saved net  5\n",
      "Saved net  6\n",
      "Saved net  7\n",
      "Saved net  8\n",
      "Saved net  9\n",
      "Saved net  10\n",
      "Saved net  11\n",
      "Saved net  12\n",
      "Saved net  13\n",
      "Saved net  14\n",
      "Saved net  15\n",
      "Saved net  16\n",
      "Saved net  17\n",
      "Saved net  18\n",
      "Saved net  19\n",
      "Saved net  20\n",
      "Saved net  21\n",
      "Saved net  22\n",
      "Saved net  23\n",
      "Saved net  24\n",
      "Saved net  25\n",
      "Saved net  26\n",
      "Saved net  27\n",
      "Saved net  28\n",
      "Saved net  29\n",
      "==================================================================================\n",
      "Starting dataset  pm10\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type NetX. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Saved net  0\n",
      "Saved net  1\n",
      "Saved net  2\n",
      "Saved net  3\n",
      "Saved net  4\n",
      "Saved net  5\n",
      "Saved net  6\n",
      "Saved net  7\n",
      "Saved net  8\n",
      "Saved net  9\n",
      "Saved net  10\n",
      "Saved net  11\n",
      "Saved net  12\n",
      "Saved net  13\n",
      "Saved net  14\n",
      "Saved net  15\n",
      "Saved net  16\n",
      "Saved net  17\n",
      "Saved net  18\n",
      "Saved net  19\n",
      "Saved net  20\n",
      "Saved net  21\n",
      "Saved net  22\n",
      "Saved net  23\n",
      "Saved net  24\n",
      "Saved net  25\n",
      "Saved net  26\n",
      "Saved net  27\n",
      "Saved net  28\n",
      "Saved net  29\n",
      "==================================================================================\n",
      "Starting dataset  prnn_synth\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type NetX. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Saved net  0\n",
      "Saved net  1\n",
      "Saved net  2\n",
      "Saved net  3\n",
      "Saved net  4\n",
      "Saved net  5\n",
      "Saved net  6\n",
      "Saved net  7\n",
      "Saved net  8\n",
      "Saved net  9\n",
      "Saved net  10\n",
      "Saved net  11\n",
      "Saved net  12\n",
      "Saved net  13\n",
      "Saved net  14\n",
      "Saved net  15\n",
      "Saved net  16\n",
      "Saved net  17\n",
      "Saved net  18\n",
      "Saved net  19\n",
      "Saved net  20\n",
      "Saved net  21\n",
      "Saved net  22\n",
      "Saved net  23\n",
      "Saved net  24\n",
      "Saved net  25\n",
      "Saved net  26\n",
      "Saved net  27\n",
      "Saved net  28\n",
      "Saved net  29\n",
      "==================================================================================\n",
      "Starting dataset  rabe_131\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type NetX. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Saved net  0\n",
      "Saved net  1\n",
      "Saved net  2\n",
      "Saved net  3\n",
      "Saved net  4\n",
      "Saved net  5\n",
      "Saved net  6\n",
      "Saved net  7\n",
      "Saved net  8\n",
      "Saved net  9\n",
      "Saved net  10\n",
      "Saved net  11\n",
      "Saved net  12\n",
      "Saved net  13\n",
      "Saved net  14\n",
      "Saved net  15\n",
      "Saved net  16\n",
      "Saved net  17\n",
      "Saved net  18\n",
      "Saved net  19\n",
      "Saved net  20\n",
      "Saved net  21\n",
      "Saved net  22\n",
      "Saved net  23\n",
      "Saved net  24\n",
      "Saved net  25\n",
      "Saved net  26\n",
      "Saved net  27\n",
      "Saved net  28\n",
      "Saved net  29\n",
      "==================================================================================\n",
      "Starting dataset  rmftsa_sleepdata\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type NetX. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Saved net  0\n",
      "Saved net  1\n",
      "Saved net  2\n",
      "Saved net  3\n",
      "Saved net  4\n",
      "Saved net  5\n",
      "Saved net  6\n",
      "Saved net  7\n",
      "Saved net  8\n",
      "Saved net  9\n",
      "Saved net  10\n",
      "Saved net  11\n",
      "Saved net  12\n",
      "Saved net  13\n",
      "Saved net  14\n",
      "Saved net  15\n",
      "Saved net  16\n",
      "Saved net  17\n",
      "Saved net  18\n",
      "Saved net  19\n",
      "Saved net  20\n",
      "Saved net  21\n",
      "Saved net  22\n",
      "Saved net  23\n",
      "Saved net  24\n",
      "Saved net  25\n",
      "Saved net  26\n",
      "Saved net  27\n",
      "Saved net  28\n",
      "Saved net  29\n",
      "==================================================================================\n",
      "Starting dataset  schlvote\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type NetX. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Saved net  0\n",
      "Saved net  1\n",
      "Saved net  2\n",
      "Saved net  3\n",
      "Saved net  4\n",
      "Saved net  5\n",
      "Saved net  6\n",
      "Saved net  7\n",
      "Saved net  8\n",
      "Saved net  9\n",
      "Saved net  10\n",
      "Saved net  11\n",
      "Saved net  12\n",
      "Saved net  13\n",
      "Saved net  14\n",
      "Saved net  15\n",
      "Saved net  16\n",
      "Saved net  17\n",
      "Saved net  18\n",
      "Saved net  19\n",
      "Saved net  20\n",
      "Saved net  21\n",
      "Saved net  22\n",
      "Saved net  23\n",
      "Saved net  24\n",
      "Saved net  25\n",
      "Saved net  26\n",
      "Saved net  27\n",
      "Saved net  28\n",
      "Saved net  29\n",
      "==================================================================================\n",
      "Starting dataset  tae\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type NetX. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Saved net  0\n",
      "Saved net  1\n",
      "Saved net  2\n",
      "Saved net  3\n",
      "Saved net  4\n",
      "Saved net  5\n",
      "Saved net  6\n",
      "Saved net  7\n",
      "Saved net  8\n",
      "Saved net  9\n",
      "Saved net  10\n",
      "Saved net  11\n",
      "Saved net  12\n",
      "Saved net  13\n",
      "Saved net  14\n",
      "Saved net  15\n",
      "Saved net  16\n",
      "Saved net  17\n",
      "Saved net  18\n",
      "Saved net  19\n",
      "Saved net  20\n",
      "Saved net  21\n",
      "Saved net  22\n",
      "Saved net  23\n",
      "Saved net  24\n",
      "Saved net  25\n",
      "Saved net  26\n",
      "Saved net  27\n",
      "Saved net  28\n",
      "Saved net  29\n",
      "==================================================================================\n",
      "Starting dataset  teachingAssistant\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type NetX. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Saved net  0\n",
      "Saved net  1\n",
      "Saved net  2\n",
      "Saved net  3\n",
      "Saved net  4\n",
      "Saved net  5\n",
      "Saved net  6\n",
      "Saved net  7\n",
      "Saved net  8\n",
      "Saved net  9\n",
      "Saved net  10\n",
      "Saved net  11\n",
      "Saved net  12\n",
      "Saved net  13\n",
      "Saved net  14\n",
      "Saved net  15\n",
      "Saved net  16\n",
      "Saved net  17\n",
      "Saved net  18\n",
      "Saved net  19\n",
      "Saved net  20\n",
      "Saved net  21\n",
      "Saved net  22\n",
      "Saved net  23\n",
      "Saved net  24\n",
      "Saved net  25\n",
      "Saved net  26\n",
      "Saved net  27\n",
      "Saved net  28\n",
      "Saved net  29\n",
      "==================================================================================\n",
      "Starting dataset  transplant\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type NetX. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Saved net  0\n",
      "Saved net  1\n",
      "Saved net  2\n",
      "Saved net  3\n",
      "Saved net  4\n",
      "Saved net  5\n",
      "Saved net  6\n",
      "Saved net  7\n",
      "Saved net  8\n",
      "Saved net  9\n",
      "Saved net  10\n",
      "Saved net  11\n",
      "Saved net  12\n",
      "Saved net  13\n",
      "Saved net  14\n",
      "Saved net  15\n",
      "Saved net  16\n",
      "Saved net  17\n",
      "Saved net  18\n",
      "Saved net  19\n",
      "Saved net  20\n",
      "Saved net  21\n",
      "Saved net  22\n",
      "Saved net  23\n",
      "Saved net  24\n",
      "Saved net  25\n",
      "Saved net  26\n",
      "Saved net  27\n",
      "Saved net  28\n",
      "Saved net  29\n",
      "==================================================================================\n",
      "Starting dataset  triazines\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type NetX. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Saved net  0\n",
      "Saved net  1\n",
      "Saved net  2\n",
      "Saved net  3\n",
      "Saved net  4\n",
      "Saved net  5\n",
      "Saved net  6\n",
      "Saved net  7\n",
      "Saved net  8\n",
      "Saved net  9\n",
      "Saved net  10\n",
      "Saved net  11\n",
      "Saved net  12\n",
      "Saved net  13\n",
      "Saved net  14\n",
      "Saved net  15\n",
      "Saved net  16\n",
      "Saved net  17\n",
      "Saved net  18\n",
      "Saved net  19\n",
      "Saved net  20\n",
      "Saved net  21\n",
      "Saved net  22\n",
      "Saved net  23\n",
      "Saved net  24\n",
      "Saved net  25\n",
      "Saved net  26\n",
      "Saved net  27\n",
      "Saved net  28\n",
      "Saved net  29\n",
      "==================================================================================\n",
      "Starting dataset  veteran\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type NetX. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Saved net  0\n",
      "Saved net  1\n",
      "Saved net  2\n",
      "Saved net  3\n",
      "Saved net  4\n",
      "Saved net  5\n",
      "Saved net  6\n",
      "Saved net  7\n",
      "Saved net  8\n",
      "Saved net  9\n",
      "Saved net  10\n",
      "Saved net  11\n",
      "Saved net  12\n",
      "Saved net  13\n",
      "Saved net  14\n",
      "Saved net  15\n",
      "Saved net  16\n",
      "Saved net  17\n",
      "Saved net  18\n",
      "Saved net  19\n",
      "Saved net  20\n",
      "Saved net  21\n",
      "Saved net  22\n",
      "Saved net  23\n",
      "Saved net  24\n",
      "Saved net  25\n",
      "Saved net  26\n",
      "Saved net  27\n",
      "Saved net  28\n",
      "Saved net  29\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Egeay-H9trL3",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "outputId": "cb10e681-091f-48cd-ca29-1e9bc3224b57"
   },
   "source": [
    "# import os\n",
    "# import zipfile\n",
    "\n",
    "# def zipdir(path, ziph):\n",
    "#     # ziph is zipfile handle\n",
    "#     for root, dirs, files in os.walk(path):\n",
    "#         for file in files:\n",
    "#             ziph.write(os.path.join(root, file))\n",
    "\n",
    "# zipf = zipfile.ZipFile('/content/drive/My Drive/Fully Connected Training/Classification/Classification.zip', 'w', zipfile.ZIP_DEFLATED)\n",
    "# zipdir('/content/drive/My Drive/Fully Connected Training/Classification/', zipf)\n",
    "# zipf.close()"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6110ac136136>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mzipf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Fully Connected Training/Classification/Classification.zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZIP_DEFLATED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mzipdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Fully Connected Training/Classification/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzipf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mzipf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-6110ac136136>\u001b[0m in \u001b[0;36mzipdir\u001b[0;34m(path, ziph)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mziph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mzipf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Fully Connected Training/Classification/Classification.zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZIP_DEFLATED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, filename, arcname, compress_type)\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1645\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m                 \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwritestr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzinfo_or_arcname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/shutil.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mfdst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_samefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0mnbytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file_size\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_crc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrc32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_crc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compressor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ]
  }
 ]
}