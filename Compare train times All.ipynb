{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from tensorflow.python.summary.summary_iterator import summary_iterator\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from collections import Counter\n",
    "import datetime\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = \"./models/Reinforce_One_Dataset/\"\n",
    "datasets = list(map(os.path.basename, glob(r\"OneDatasetLearning/Classification/*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = []\n",
    "all_sizes = []\n",
    "\n",
    "for curr_d in datasets:\n",
    "    s, f = pd.read_csv(f'OneDatasetLearning/Classification/{curr_d}/{curr_d}.csv').shape\n",
    "    all_sizes.append(s)\n",
    "    all_features.append(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_to_feature_size = dict([(x, all_features[idx]) for idx, x in enumerate(datasets)])\n",
    "dataset_to_size = dict([(x, all_sizes[idx]) for idx, x in enumerate(datasets)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_min_max(l):\n",
    "    l.remove(min(l))\n",
    "    l.remove(max(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_logs_folders = glob(\"runs2/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs_lambdas = {\n",
    "#     'NEON 4': lambda l: list(filter(lambda x: 'with_loop' in x and\n",
    "#                                                'Random_Actions' not in x and\n",
    "#                                                'single_test' not in x and\n",
    "#                                                'warmup' not in x, l)),\n",
    "    'NEON 4': lambda l: list(filter(lambda x: 'with_loop' in x and\n",
    "                                         'Random_Actions' not in x and\n",
    "                                         'single_test' not in x and\n",
    "                                         'warmup' in x, l)),\n",
    "#     'NEON 1': lambda l: list(filter(lambda x: 'with_loop' not in x and \n",
    "#                                      'Random_Actions' not in x and \n",
    "#                                      'LAP' not in x and\n",
    "#                                      'pruning' not in x and\n",
    "#                                      'Combined' not in x and\n",
    "#                                      'ADMM' not in x and\n",
    "#                                      'AMC' not in x and\n",
    "#                                      'warmup' not in x, l)),    \n",
    "    'NEON 1': lambda l: list(filter(lambda x: 'with_loop' not in x and \n",
    "                                         'Random_Actions' not in x and \n",
    "                                         'LAP' not in x and\n",
    "                                         'pruning' not in x and\n",
    "                                         'Combined' not in x and\n",
    "                                         'ADMM' not in x and\n",
    "                                         'AMC' not in x and\n",
    "                                         'warmup' in x, l))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = list(map(lambda x: f'{x} ({dataset_to_size[x]})', datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta_by_log(log_paths):\n",
    "# log_paths = glob(os.path.join(a[0], \"*\"))\n",
    "    min_of_all_logs = datetime.datetime.max\n",
    "    max_of_all_logs = datetime.datetime.min\n",
    "    max_log = None\n",
    "\n",
    "    for log_path in log_paths:    \n",
    "        curr_log = list(summary_iterator(log_path))\n",
    "        if len(curr_log) == 1:continue\n",
    "        last_log = datetime.datetime.fromtimestamp(curr_log[-1].wall_time)\n",
    "        first_log = datetime.datetime.fromtimestamp(curr_log[0].wall_time)\n",
    "\n",
    "        if min_of_all_logs > first_log:\n",
    "            min_of_all_logs = first_log\n",
    "\n",
    "        if max_of_all_logs < last_log:\n",
    "            max_of_all_logs = last_log\n",
    "            max_log = curr_log[-1]\n",
    "\n",
    "\n",
    "    delta_last_to_first = (max_of_all_logs - min_of_all_logs).total_seconds() / 60 / 60\n",
    "    average_evaluation_time = (delta_last_to_first * 60) / max_log.step\n",
    "    return delta_last_to_first, average_evaluation_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_value_to_correct_lst(small, medium, large, value, ds):\n",
    "    if dataset_to_size[ds] <= 5000:\n",
    "        small.append(value)\n",
    "    elif dataset_to_size[ds] <= 30000:\n",
    "        medium.append(value)\n",
    "    else:\n",
    "        large.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lior\\anaconda3\\lib\\site-packages\\tensorflow\\python\\summary\\summary_iterator.py:68: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    }
   ],
   "source": [
    "all_hyper_params_possibilities = ['0', '1', '5', '50']\n",
    "\n",
    "for name, filter_func in all_runs_lambdas.items():\n",
    "    small_training = []\n",
    "    medium_training = []\n",
    "    large_training = []\n",
    "    \n",
    "    small_evaluation = []\n",
    "    medium_evaluation = []\n",
    "    large_evaluation = []    \n",
    "    relevant_logs = filter_func(all_logs_folders)\n",
    "\n",
    "    for idx, curr_acc_hp in enumerate(all_hyper_params_possibilities):        \n",
    "        curr_group = list(filter(lambda x: re.search(r'acc_reduction_(\\d{1,2})', x).group(1) == curr_acc_hp, \n",
    "                                 relevant_logs))        \n",
    "        for curr_ds in datasets:\n",
    "            curr_log_folder = list(filter(lambda x: curr_ds in x, curr_group))[0]\n",
    "            log_path = glob(os.path.join(curr_log_folder, \"*\"))\n",
    "            curr_delta = get_delta_by_log(log_path)\n",
    "            add_value_to_correct_lst(small_training, medium_training, large_training, curr_delta[0], curr_ds)            \n",
    "            add_value_to_correct_lst(small_evaluation, medium_evaluation, large_evaluation, curr_delta[1], curr_ds)\n",
    "        \n",
    "\n",
    "    for _ in range(4):\n",
    "        remove_min_max(small_training)\n",
    "        remove_min_max(medium_training)\n",
    "        remove_min_max(large_training)\n",
    "        remove_min_max(small_evaluation)\n",
    "        remove_min_max(medium_evaluation)\n",
    "        remove_min_max(large_evaluation)\n",
    "\n",
    "    all_data.append([f'{name}', np.average(small_training), np.average(small_evaluation),\n",
    "                    np.average(medium_training), np.average(medium_evaluation),\n",
    "                    np.average(large_training), np.average(large_evaluation)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_folder = r\"./times\"\n",
    "all_times = glob(os.path.join(time_folder, \"*\"))\n",
    "\n",
    "times_path = list(filter(lambda x: \"ADMM\" in x, all_times))[0]\n",
    "time_df = pd.read_csv(times_path)\n",
    "\n",
    "time_df['ds_size'] = time_df.Dataset.apply(dataset_to_size.get)\n",
    "time_df['time_in_hours'] = time_df.time / 60 / 60\n",
    "\n",
    "small_times = time_df[time_df.ds_size <= 5000]\n",
    "medium_times = time_df[(time_df.ds_size > 5000) & (time_df.ds_size <= 30000)]\n",
    "large_times = time_df[time_df.ds_size > 30000]\n",
    "\n",
    "all_data.append([f'ADMM', \"\", small_times.time_in_hours.mean(),\n",
    "                \"\", medium_times.time_in_hours.mean(),\n",
    "                \"\", large_times.time_in_hours.mean()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAP 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_folder = r\"./times\"\n",
    "all_times = glob(os.path.join(time_folder, \"*\"))\n",
    "\n",
    "times_path = list(filter(lambda x: \"LAP2_1\" in x, all_times))[0]\n",
    "time_df = pd.read_csv(times_path)\n",
    "\n",
    "time_df['ds_size'] = time_df.Dataset.apply(dataset_to_size.get)\n",
    "time_df['time_in_hours'] = time_df.time / 60 / 60\n",
    "\n",
    "small_times = time_df[time_df.ds_size <= 5000]\n",
    "medium_times = time_df[(time_df.ds_size > 5000) & (time_df.ds_size <= 30000)]\n",
    "large_times = time_df[time_df.ds_size > 30000]\n",
    "\n",
    "all_data.append([f'LAP 1', \"\", small_times.time_in_hours.mean(),\n",
    "                \"\", medium_times.time_in_hours.mean(),\n",
    "                \"\", large_times.time_in_hours.mean()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAP 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_folder = r\"./times\"\n",
    "all_times = glob(os.path.join(time_folder, \"*\"))\n",
    "\n",
    "times_path = list(filter(lambda x: \"LAP2_4\" in x, all_times))[0]\n",
    "time_df = pd.read_csv(times_path)\n",
    "\n",
    "time_df['ds_size'] = time_df.Dataset.apply(dataset_to_size.get)\n",
    "time_df['time_in_hours'] = time_df.time / 60 / 60\n",
    "\n",
    "small_times = time_df[time_df.ds_size <= 5000]\n",
    "medium_times = time_df[(time_df.ds_size > 5000) & (time_df.ds_size <= 30000)]\n",
    "large_times = time_df[time_df.ds_size > 30000]\n",
    "\n",
    "all_data.append([f'LAP 4', \"\", small_times.time_in_hours.mean(),\n",
    "                \"\", medium_times.time_in_hours.mean(),\n",
    "                \"\", large_times.time_in_hours.mean()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAP 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_folder = r\"./times\"\n",
    "all_times = glob(os.path.join(time_folder, \"*\"))\n",
    "\n",
    "times_path = list(filter(lambda x: \"LAP2_10\" in x, all_times))[0]\n",
    "time_df = pd.read_csv(times_path)\n",
    "\n",
    "time_df['ds_size'] = time_df.Dataset.apply(dataset_to_size.get)\n",
    "time_df['time_in_hours'] = time_df.time / 60 / 60\n",
    "\n",
    "small_times = time_df[time_df.ds_size <= 5000]\n",
    "medium_times = time_df[(time_df.ds_size > 5000) & (time_df.ds_size <= 30000)]\n",
    "large_times = time_df[time_df.ds_size > 30000]\n",
    "\n",
    "all_data.append([f'LAP 10', \"\", small_times.time_in_hours.mean(),\n",
    "                \"\", medium_times.time_in_hours.mean(),\n",
    "                \"\", large_times.time_in_hours.mean()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_folder = r\"./times\"\n",
    "all_times = glob(os.path.join(time_folder, \"*\"))\n",
    "\n",
    "times_path = list(filter(lambda x: \"pruning\" in x, all_times))[0]\n",
    "time_df = pd.read_csv(times_path)\n",
    "\n",
    "time_df['ds_size'] = time_df.Dataset.apply(dataset_to_size.get)\n",
    "time_df['time_in_hours'] = time_df.time / 60 / 60\n",
    "\n",
    "small_times = time_df[time_df.ds_size <= 5000]\n",
    "medium_times = time_df[(time_df.ds_size > 5000) & (time_df.ds_size <= 30000)]\n",
    "large_times = time_df[time_df.ds_size > 30000]\n",
    "\n",
    "all_data.append([f'Pruning', \"\", small_times.time_in_hours.mean(),\n",
    "                \"\", medium_times.time_in_hours.mean(),\n",
    "                \"\", large_times.time_in_hours.mean()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEON 4</td>\n",
       "      <td>3.39711</td>\n",
       "      <td>0.651204</td>\n",
       "      <td>25.3498</td>\n",
       "      <td>4.859380</td>\n",
       "      <td>57.9172</td>\n",
       "      <td>13.324788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEON 1</td>\n",
       "      <td>0.556331</td>\n",
       "      <td>0.106645</td>\n",
       "      <td>4.17152</td>\n",
       "      <td>0.799652</td>\n",
       "      <td>11.9874</td>\n",
       "      <td>2.297901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADMM</td>\n",
       "      <td></td>\n",
       "      <td>0.011637</td>\n",
       "      <td></td>\n",
       "      <td>0.111004</td>\n",
       "      <td></td>\n",
       "      <td>0.264999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LAP 1</td>\n",
       "      <td></td>\n",
       "      <td>0.085758</td>\n",
       "      <td></td>\n",
       "      <td>0.085931</td>\n",
       "      <td></td>\n",
       "      <td>0.087914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LAP 4</td>\n",
       "      <td></td>\n",
       "      <td>0.085529</td>\n",
       "      <td></td>\n",
       "      <td>0.087503</td>\n",
       "      <td></td>\n",
       "      <td>0.090471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LAP 10</td>\n",
       "      <td></td>\n",
       "      <td>0.085087</td>\n",
       "      <td></td>\n",
       "      <td>0.087004</td>\n",
       "      <td></td>\n",
       "      <td>0.088746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pruning</td>\n",
       "      <td></td>\n",
       "      <td>0.030185</td>\n",
       "      <td></td>\n",
       "      <td>0.360345</td>\n",
       "      <td></td>\n",
       "      <td>0.793287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2        3         4        5          6\n",
       "0   NEON 4   3.39711  0.651204  25.3498  4.859380  57.9172  13.324788\n",
       "1   NEON 1  0.556331  0.106645  4.17152  0.799652  11.9874   2.297901\n",
       "2     ADMM            0.011637           0.111004            0.264999\n",
       "3    LAP 1            0.085758           0.085931            0.087914\n",
       "4    LAP 4            0.085529           0.087503            0.090471\n",
       "5   LAP 10            0.085087           0.087004            0.088746\n",
       "6  Pruning            0.030185           0.360345            0.793287"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMC 10 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_folder = r\"./times\"\n",
    "all_times = glob(os.path.join(time_folder, \"*\"))\n",
    "\n",
    "times_path = list(filter(lambda x: \"AMC\" in x, all_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_path_datasets = list(map(lambda x: re.search(\"10iters_(.*).csv\" ,x).group(1), times_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_column = np.array(list(zip(all_path_datasets, all_path_datasets))).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_amc_data = pd.concat(list(map(pd.read_csv,times_path)))\n",
    "all_amc_data['ds'] = dataset_column\n",
    "all_amc_data['ds_size'] = all_amc_data.ds.apply(dataset_to_size.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_amc_data = all_amc_data[all_amc_data.Dataset == 'train']\n",
    "eval_amc_data = all_amc_data[all_amc_data.Dataset == 'eval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-ddd4a1b021e0>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  training_amc_data['time_in_minutes'] = training_amc_data.time / 60 / 60\n",
      "<ipython-input-24-ddd4a1b021e0>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eval_amc_data['time_in_hours'] = eval_amc_data.time / 60\n"
     ]
    }
   ],
   "source": [
    "training_amc_data['time_in_minutes'] = training_amc_data.time / 60 / 60\n",
    "eval_amc_data['time_in_hours'] = eval_amc_data.time / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_small_times = training_amc_data[training_amc_data.ds_size <= 5000]\n",
    "training_medium_times = training_amc_data[(training_amc_data.ds_size > 5000) & (training_amc_data.ds_size <= 30000)]\n",
    "training_large_times = training_amc_data[training_amc_data.ds_size > 30000]\n",
    "\n",
    "eval_small_times = eval_amc_data[eval_amc_data.ds_size <= 5000]\n",
    "eval_medium_times = eval_amc_data[(eval_amc_data.ds_size > 5000) & (eval_amc_data.ds_size <= 30000)]\n",
    "eval_large_times = eval_amc_data[eval_amc_data.ds_size > 30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.append([f'AMC 10 iters', training_small_times.time_in_minutes.mean(), eval_small_times.time_in_hours.mean(),\n",
    "                training_medium_times.time_in_minutes.mean(), eval_medium_times.time_in_hours.mean(),\n",
    "                training_large_times.time_in_minutes.mean(), eval_large_times.time_in_hours.mean()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEON 4</td>\n",
       "      <td>3.39711</td>\n",
       "      <td>0.651204</td>\n",
       "      <td>25.3498</td>\n",
       "      <td>4.859380</td>\n",
       "      <td>57.9172</td>\n",
       "      <td>13.324788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEON 1</td>\n",
       "      <td>0.556331</td>\n",
       "      <td>0.106645</td>\n",
       "      <td>4.17152</td>\n",
       "      <td>0.799652</td>\n",
       "      <td>11.9874</td>\n",
       "      <td>2.297901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADMM</td>\n",
       "      <td></td>\n",
       "      <td>0.011637</td>\n",
       "      <td></td>\n",
       "      <td>0.111004</td>\n",
       "      <td></td>\n",
       "      <td>0.264999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LAP 1</td>\n",
       "      <td></td>\n",
       "      <td>0.085758</td>\n",
       "      <td></td>\n",
       "      <td>0.085931</td>\n",
       "      <td></td>\n",
       "      <td>0.087914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LAP 4</td>\n",
       "      <td></td>\n",
       "      <td>0.085529</td>\n",
       "      <td></td>\n",
       "      <td>0.087503</td>\n",
       "      <td></td>\n",
       "      <td>0.090471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LAP 10</td>\n",
       "      <td></td>\n",
       "      <td>0.085087</td>\n",
       "      <td></td>\n",
       "      <td>0.087004</td>\n",
       "      <td></td>\n",
       "      <td>0.088746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pruning</td>\n",
       "      <td></td>\n",
       "      <td>0.030185</td>\n",
       "      <td></td>\n",
       "      <td>0.360345</td>\n",
       "      <td></td>\n",
       "      <td>0.793287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AMC 10 iters</td>\n",
       "      <td>0.239506</td>\n",
       "      <td>0.026960</td>\n",
       "      <td>0.800172</td>\n",
       "      <td>0.241931</td>\n",
       "      <td>1.20739</td>\n",
       "      <td>0.755098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4        5          6\n",
       "0        NEON 4   3.39711  0.651204   25.3498  4.859380  57.9172  13.324788\n",
       "1        NEON 1  0.556331  0.106645   4.17152  0.799652  11.9874   2.297901\n",
       "2          ADMM            0.011637            0.111004            0.264999\n",
       "3         LAP 1            0.085758            0.085931            0.087914\n",
       "4         LAP 4            0.085529            0.087503            0.090471\n",
       "5        LAP 10            0.085087            0.087004            0.088746\n",
       "6       Pruning            0.030185            0.360345            0.793287\n",
       "7  AMC 10 iters  0.239506  0.026960  0.800172  0.241931  1.20739   0.755098"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(all_data).to_csv(\"times comparison.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
